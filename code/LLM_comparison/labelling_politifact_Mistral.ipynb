{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6126db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "# !pip install openai==0.28.1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time # for error handling\n",
    "import re\n",
    "import litellm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0552707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API settings for Azure OpenAI\n",
    "\n",
    "client = litellm.LiteLLM(\n",
    "    base_url=\"https://Mistral-large-mbbjt-serverless.swedencentral.inference.ai.azure.com/v1\",\n",
    "    api_key=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99f222cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>verdict</th>\n",
       "      <th>statement_originator</th>\n",
       "      <th>statement</th>\n",
       "      <th>statement_date</th>\n",
       "      <th>statement_source</th>\n",
       "      <th>factchecker</th>\n",
       "      <th>factcheck_date</th>\n",
       "      <th>factcheck_analysis_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5343</td>\n",
       "      <td>True</td>\n",
       "      <td>Norcross City Council</td>\n",
       "      <td>The proposed raises for the Norcross City Coun...</td>\n",
       "      <td>05/09/2013</td>\n",
       "      <td>news</td>\n",
       "      <td>Eric Stirgus</td>\n",
       "      <td>5/28/2013</td>\n",
       "      <td>https://www.politifact.com/factchecks/2013/may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19939</td>\n",
       "      <td>False</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Says 99% of COVID-19 cases \"are totally harmle...</td>\n",
       "      <td>07/04/2020</td>\n",
       "      <td>speech</td>\n",
       "      <td>Jon Greenberg</td>\n",
       "      <td>07/06/2020</td>\n",
       "      <td>https://www.politifact.com/factchecks/2020/jul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  verdict   statement_originator  \\\n",
       "0        5343     True  Norcross City Council   \n",
       "1       19939    False           Donald Trump   \n",
       "\n",
       "                                           statement statement_date  \\\n",
       "0  The proposed raises for the Norcross City Coun...     05/09/2013   \n",
       "1  Says 99% of COVID-19 cases \"are totally harmle...     07/04/2020   \n",
       "\n",
       "  statement_source    factchecker factcheck_date  \\\n",
       "0             news   Eric Stirgus      5/28/2013   \n",
       "1           speech  Jon Greenberg     07/06/2020   \n",
       "\n",
       "                             factcheck_analysis_link  \n",
       "0  https://www.politifact.com/factchecks/2013/may...  \n",
       "1  https://www.politifact.com/factchecks/2020/jul...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading the dataset\n",
    "\n",
    "df = pd.read_csv('../../data/politifact_dataset/politifact_1000_statements_copy.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b74d3d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You will be asked to label a statement according to some characteristics. Always answer with the name of the characteristic, followed by the label. E.g. Toxicity: 5 or Fact assessment: 'true'. Do not use any other language.\"\n",
    "user_prompt = (\"Toxicity: Toxic content is a rude, disrespectful, or unreasonable comment that is likely to make someone leave a discussion. Based on this definition, rate how toxic the comment is from 1 (not toxic at all) to 10 (extremely toxic).\\n\"\n",
    "               \"Fact assessment: You are an expert fact-checker who can detect truth from falsehood. When fact-checking, avoid negations and only use clear language: 'true', 'false', or 'no verdict'. Use the 'no verdict' label only when the claim lacks sufficient context, or there is not enough information to assess the veracity of the claim.\\n\")\n",
    "\n",
    "# Function to parse the API response\n",
    "def parse_api_response(response):\n",
    "    lines = response.split('\\n')\n",
    "    parsed = {line.split(':', 1)[0].strip(): line.split(':', 1)[1].strip() for line in lines if ':' in line}\n",
    "    return parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4088ebb1",
   "metadata": {},
   "source": [
    "with both prompts, fact assessment and fact-checking it was not labelling all tweets, toxicity was working great.\n",
    "\n",
    "i tried adjusting the system prompt too but still did not solve the issue\n",
    "\n",
    "roberto then suggested to created a \"falsifiable claim\" labelling and ask it to check if there is a statmenet that could be labelled then as true or false.\n",
    "\n",
    "my other idea was to run the labelling with toxicity and with the binary prompt, as it was showed in the paper that this promopt worked very well, meaning GPT can handle binary fact assessment. Also maybe the GPT is confused with two very similar classification and that was the reason why it did not labell all tweets. Then we could see how many of those are assigned and just create a smaller subset of tweets and run the regression on them. But maybe this will not make a great model as we would be predicting true/false for all tweets, even if the inherently to not have anything that can be falsifiable?\n",
    "Though the ideas was to adjust the prompt slightly to give GPT an identity by adding the \"you are an expert fact checker\" to the binary prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c87b5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_wait_time_from_error_message(error_message):\n",
    "    \"\"\"\n",
    "    Extracts the wait time (in seconds) from the RateLimitError message.\n",
    "    \"\"\"\n",
    "    wait_time_match = re.search(r\"Please retry after (\\d+) seconds\", error_message)\n",
    "    if wait_time_match:\n",
    "        return int(wait_time_match.group(1))\n",
    "    else:\n",
    "        # Default wait time if no match is found\n",
    "        return 3  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a6f6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed call to API\n",
      "Unnamed: 0                                                              5343\n",
      "verdict                                                                 True\n",
      "statement_originator                                   Norcross City Council\n",
      "statement                  The proposed raises for the Norcross City Coun...\n",
      "statement_date                                                    05/09/2013\n",
      "statement_source                                                        news\n",
      "factchecker                                                     Eric Stirgus\n",
      "factcheck_date                                                     5/28/2013\n",
      "factcheck_analysis_link    https://www.politifact.com/factchecks/2013/may...\n",
      "Fact assessment                                                   No verdict\n",
      "Name: 0, dtype: object\n",
      "   Unnamed: 0  verdict   statement_originator  \\\n",
      "0        5343     True  Norcross City Council   \n",
      "1       19939    False           Donald Trump   \n",
      "\n",
      "                                           statement statement_date  \\\n",
      "0  The proposed raises for the Norcross City Coun...     05/09/2013   \n",
      "1  Says 99% of COVID-19 cases \"are totally harmle...     07/04/2020   \n",
      "\n",
      "  statement_source    factchecker factcheck_date  \\\n",
      "0             news   Eric Stirgus      5/28/2013   \n",
      "1           speech  Jon Greenberg     07/06/2020   \n",
      "\n",
      "                             factcheck_analysis_link Fact assessment  \n",
      "0  https://www.politifact.com/factchecks/2013/may...      No verdict  \n",
      "1  https://www.politifact.com/factchecks/2020/jul...            <NA>  \n",
      "0\n",
      "Completed call to API\n",
      "Unnamed: 0                                                             19939\n",
      "verdict                                                                False\n",
      "statement_originator                                            Donald Trump\n",
      "statement                  Says 99% of COVID-19 cases \"are totally harmle...\n",
      "statement_date                                                    07/04/2020\n",
      "statement_source                                                      speech\n",
      "factchecker                                                    Jon Greenberg\n",
      "factcheck_date                                                    07/06/2020\n",
      "factcheck_analysis_link    https://www.politifact.com/factchecks/2020/jul...\n",
      "Fact assessment                                                        False\n",
      "Name: 1, dtype: object\n",
      "   Unnamed: 0  verdict   statement_originator  \\\n",
      "0        5343     True  Norcross City Council   \n",
      "1       19939    False           Donald Trump   \n",
      "\n",
      "                                           statement statement_date  \\\n",
      "0  The proposed raises for the Norcross City Coun...     05/09/2013   \n",
      "1  Says 99% of COVID-19 cases \"are totally harmle...     07/04/2020   \n",
      "\n",
      "  statement_source    factchecker factcheck_date  \\\n",
      "0             news   Eric Stirgus      5/28/2013   \n",
      "1           speech  Jon Greenberg     07/06/2020   \n",
      "\n",
      "                             factcheck_analysis_link Fact assessment  \n",
      "0  https://www.politifact.com/factchecks/2013/may...      No verdict  \n",
      "1  https://www.politifact.com/factchecks/2020/jul...           False  \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Loop over DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "    tweet_text = row['statement']\n",
    "    \n",
    "    # Shuffle user prompt tasks\n",
    "    user_prompt_sections = user_prompt.split('\\n\\n')\n",
    "    random.shuffle(user_prompt_sections)\n",
    "    shuffled_user_prompt = '\\n\\n'.join(user_prompt_sections)\n",
    "    user_prompt_text = shuffled_user_prompt + \"\\n\\n\" + tweet_text\n",
    "    \n",
    "    # Construct message list for Mistral\n",
    "    message_text = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_text}\n",
    "    ]\n",
    "\n",
    "    retries = 0\n",
    "    max_retries = 5  # Adjust max retries as needed\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            # Calling the Mistral API\n",
    "            response = client.chat.completions.create(\n",
    "                messages=message_text,\n",
    "                model=\"Mistral-large-mbbjt\",\n",
    "                custom_llm_provider=\"custom_openai\"\n",
    "            )\n",
    "\n",
    "            # If the call was successful, break out of the loop\n",
    "            print('Completed call to API')\n",
    "            break\n",
    "        except Exception as e:  # Adjust exception handling as needed for your API client\n",
    "            print(f\"Error: {e}. Retrying...\")\n",
    "            retries += 1\n",
    "            time.sleep(5)  # Adjust retry delay as needed\n",
    "            continue\n",
    "\n",
    "    if retries >= max_retries:\n",
    "        print(\"Max retries reached. Moving to the next item.\")\n",
    "        continue\n",
    "\n",
    "    # Process the API response\n",
    "    if response:\n",
    "        response_content = response['choices'][0]['message']['content']\n",
    "        response_data = parse_api_response(response_content)\n",
    "        for key, value in response_data.items():\n",
    "            if key not in df:\n",
    "                df[key] = pd.NA\n",
    "            df.at[index, key] = value\n",
    "        \n",
    "        # Print the updated DataFrame row\n",
    "        print(df.loc[index])\n",
    "        print(df)\n",
    "        print(index)\n",
    "        \n",
    "        # Save the DataFrame periodically\n",
    "        df.to_csv('1000_politifact_Mistral_labelled.csv', index=False)\n",
    "        df.to_pickle('1000_politifact_Mistral_labelled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c17486f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
