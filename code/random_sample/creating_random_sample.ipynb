{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     41\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename)\n\u001b[0;32m---> 42\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m         dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     45\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bert_envv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bert_envv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bert_envv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bert_envv/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bert_envv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bert_envv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bert_envv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1036\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bert_envv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1090\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bert_envv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1165\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bert_envv/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1335\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;66;03m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;66;03m#  here too.\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;66;03m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;66;03m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1331\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1332\u001b[0m     )\n\u001b[0;32m-> 1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "\n",
    "# Path to the directory containing the CSV files\n",
    "directory = \"../../data/1.Tweets_US.election.2020_and_Jan6\"\n",
    "\n",
    "# List to store the file paths\n",
    "csv_files_paths = []\n",
    "\n",
    "# Generate file paths for each date\n",
    "start_date = datetime(2020, 7, 24)\n",
    "end_date = datetime(2021, 5, 11)\n",
    "\n",
    "\n",
    "# Load or create sampled indices from/to JSON file\n",
    "def load_sampled_indices():\n",
    "    try:\n",
    "        with open(\"sampled_indices.json\", \"r\") as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "def save_sampled_indices(sampled_indices):\n",
    "    with open(\"sampled_indices.json\", \"w\") as file:\n",
    "        json.dump(sampled_indices, file)\n",
    "\n",
    "# List to store sampled tweets and their indices\n",
    "sampled_tweets = []\n",
    "sampled_indices = {}\n",
    "\n",
    "\n",
    "# Combine all CSV files into one dataframe\n",
    "dfs = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at_fuzzy</th>\n",
       "      <th>state_likely_tweeted_from</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>display_text_width</th>\n",
       "      <th>lang</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>favourites_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-18T01:28:40Z</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>@RealKHiveQueenB She is a Trump feminine Mini Me</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>31</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2400</td>\n",
       "      <td>2062</td>\n",
       "      <td>4</td>\n",
       "      <td>102227</td>\n",
       "      <td>156337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-18T00:55:06Z</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>@symonelyfy Thank you... Always On Camera...is...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>58</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2400</td>\n",
       "      <td>2062</td>\n",
       "      <td>4</td>\n",
       "      <td>102227</td>\n",
       "      <td>156337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-18T16:18:20Z</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>@Raymc31 @SCOTUSblog Those flight logs has Rob...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>280</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>77</td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>995</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-18T18:09:28Z</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>@realDonaldTrump You boy Justice Roberts is a ...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>227</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>77</td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>995</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-18T08:27:02Z</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>@tabbyweeks @lindelle14 @lola30006 @realDonald...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>127</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>77</td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>995</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272979</th>\n",
       "      <td>2020-12-12T04:25:37Z</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>#ReThuglican Trump cult.\\n#Prosecute #Prosecut...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>56</td>\n",
       "      <td>en</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1443</td>\n",
       "      <td>4338</td>\n",
       "      <td>5</td>\n",
       "      <td>23081</td>\n",
       "      <td>14402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272980</th>\n",
       "      <td>2020-12-12T00:02:46Z</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>@PrzElectKennedy @washingtonpost You do realiz...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>55</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>216</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "      <td>2734</td>\n",
       "      <td>32548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272981</th>\n",
       "      <td>2020-12-11T20:31:53Z</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>@SirMichael2018 @JDFranswaa @FreckledLiberty @...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>119</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>504</td>\n",
       "      <td>1834</td>\n",
       "      <td>4</td>\n",
       "      <td>15510</td>\n",
       "      <td>249940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272982</th>\n",
       "      <td>2020-12-11T18:35:48Z</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>@SirMichael2018 @JDFranswaa @FreckledLiberty @...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>69</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>504</td>\n",
       "      <td>1834</td>\n",
       "      <td>4</td>\n",
       "      <td>15510</td>\n",
       "      <td>249940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272983</th>\n",
       "      <td>2020-12-12T07:06:57Z</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>Hey democraps, I told you so. The trump is the...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>128</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>716</td>\n",
       "      <td>700</td>\n",
       "      <td>4</td>\n",
       "      <td>2081</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9272984 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at_fuzzy state_likely_tweeted_from  \\\n",
       "0        2020-12-18T01:28:40Z                   Alabama   \n",
       "1        2020-12-18T00:55:06Z                   Alabama   \n",
       "2        2020-12-18T16:18:20Z                   Alabama   \n",
       "3        2020-12-18T18:09:28Z                   Alabama   \n",
       "4        2020-12-18T08:27:02Z                   Alabama   \n",
       "...                       ...                       ...   \n",
       "9272979  2020-12-12T04:25:37Z                    Nevada   \n",
       "9272980  2020-12-12T00:02:46Z                    Nevada   \n",
       "9272981  2020-12-11T20:31:53Z                    Nevada   \n",
       "9272982  2020-12-11T18:35:48Z                    Nevada   \n",
       "9272983  2020-12-12T07:06:57Z                    Nevada   \n",
       "\n",
       "                                                      text  \\\n",
       "0         @RealKHiveQueenB She is a Trump feminine Mini Me   \n",
       "1        @symonelyfy Thank you... Always On Camera...is...   \n",
       "2        @Raymc31 @SCOTUSblog Those flight logs has Rob...   \n",
       "3        @realDonaldTrump You boy Justice Roberts is a ...   \n",
       "4        @tabbyweeks @lindelle14 @lola30006 @realDonald...   \n",
       "...                                                    ...   \n",
       "9272979  #ReThuglican Trump cult.\\n#Prosecute #Prosecut...   \n",
       "9272980  @PrzElectKennedy @washingtonpost You do realiz...   \n",
       "9272981  @SirMichael2018 @JDFranswaa @FreckledLiberty @...   \n",
       "9272982  @SirMichael2018 @JDFranswaa @FreckledLiberty @...   \n",
       "9272983  Hey democraps, I told you so. The trump is the...   \n",
       "\n",
       "                      source  display_text_width lang  favorite_count  \\\n",
       "0        Twitter for Android                  31   en               0   \n",
       "1        Twitter for Android                  58   en               1   \n",
       "2        Twitter for Android                 280   en               0   \n",
       "3        Twitter for Android                 227   en               0   \n",
       "4        Twitter for Android                 127   en               0   \n",
       "...                      ...                 ...  ...             ...   \n",
       "9272979      Twitter Web App                  56   en               6   \n",
       "9272980   Twitter for iPhone                  55   en               0   \n",
       "9272981  Twitter for Android                 119   en               1   \n",
       "9272982  Twitter for Android                  69   en               1   \n",
       "9272983  Twitter for Android                 128   en               0   \n",
       "\n",
       "         retweet_count  is_quote  followers_count  friends_count  \\\n",
       "0                    0     False             2400           2062   \n",
       "1                    0     False             2400           2062   \n",
       "2                    0     False               77            132   \n",
       "3                    0     False               77            132   \n",
       "4                    0     False               77            132   \n",
       "...                ...       ...              ...            ...   \n",
       "9272979              1      True             1443           4338   \n",
       "9272980              0     False              216            796   \n",
       "9272981              0     False              504           1834   \n",
       "9272982              0     False              504           1834   \n",
       "9272983              0     False              716            700   \n",
       "\n",
       "         listed_count  statuses_count  favourites_count  \n",
       "0                   4          102227            156337  \n",
       "1                   4          102227            156337  \n",
       "2                   3             995               516  \n",
       "3                   3             995               516  \n",
       "4                   3             995               516  \n",
       "...               ...             ...               ...  \n",
       "9272979             5           23081             14402  \n",
       "9272980             0            2734             32548  \n",
       "9272981             4           15510            249940  \n",
       "9272982             4           15510            249940  \n",
       "9272983             4            2081               211  \n",
       "\n",
       "[9272984 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if combined_df has enough rows\n",
    "if len(combined_df) >= 2000:\n",
    "    # Sample 1000 random tweets\n",
    "    sampled_idx = random.sample(range(len(combined_df)), 2000)\n",
    "    sampled_tweets = combined_df.iloc[sampled_idx]\n",
    "\n",
    "    # Store the indices of the sampled tweets\n",
    "    sampled_indices = sampled_tweets.index.tolist()\n",
    "\n",
    "    # Save the indices to a JSON file\n",
    "    with open(\"sampled_indices.json\", \"w\") as f:\n",
    "        json.dump(sampled_indices, f)\n",
    "\n",
    "    # Save the 1000 random tweets to a CSV file\n",
    "    sampled_tweets.to_csv(\"sampled_tweets.csv\", index=False)\n",
    "else:\n",
    "    print(\"Combined dataframe does not have enough rows for sampling.\")\n",
    "\n",
    "\n",
    "# Save the sampled tweets DataFrame as a pickle file\n",
    "pickle_file_path = \"all_tweets_combined_df.pkl\"\n",
    "combined_df.to_pickle(pickle_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling another 1000 random tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(additional_indices) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[1;32m     15\u001b[0m     index \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sampled_tweets) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure index is within valid range\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msampled_indices\u001b[49m:\n\u001b[1;32m     17\u001b[0m         additional_indices\u001b[38;5;241m.\u001b[39mappend(index)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Sample additional 1000 rows from DataFrame\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#not working\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Load previously sampled indices\n",
    "sampled_indices = load_sampled_indices()\n",
    "\n",
    "# Load sampled tweets DataFrame from pickle file\n",
    "sampled_tweets = pd.read_pickle(\"sampled_tweets.pkl\")\n",
    "\n",
    "# Generate new indices for additional 1000 rows\n",
    "additional_indices = []\n",
    "while len(additional_indices) < 1000:\n",
    "    index = random.randint(0, len(sampled_tweets) - 1)  # Ensure index is within valid range\n",
    "    if index not in sampled_indices:\n",
    "        additional_indices.append(index)\n",
    "\n",
    "# Sample additional 1000 rows from DataFrame\n",
    "additional_tweets = sampled_tweets.iloc[additional_indices]\n",
    "\n",
    "# Combine previously sampled tweets with newly sampled tweets\n",
    "combined_tweets = pd.concat([sampled_tweets, additional_tweets], ignore_index=True)\n",
    "\n",
    "# Save combined DataFrame to CSV file\n",
    "combined_tweets.to_csv(\"2000_random_rows.csv\", index=False)\n",
    "\n",
    "# Save combined indices to JSON file\n",
    "with open(\"sampled_indices_2000.json\", \"w\") as file:\n",
    "    json.dump(sampled_indices, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(additional_indices) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[1;32m     24\u001b[0m     index \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sampled_tweets) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure index is within valid range\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msampled_indices\u001b[49m:\n\u001b[1;32m     26\u001b[0m         additional_indices\u001b[38;5;241m.\u001b[39madd(index)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Sample additional 1000 rows from DataFrame\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Load previously sampled indices\n",
    "def load_sampled_indices():\n",
    "    try:\n",
    "        with open(\"sampled_indices.json\", \"r\") as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "\n",
    "def save_sampled_indices(sampled_indices):\n",
    "    with open(\"sampled_indices.json\", \"w\") as file:\n",
    "        json.dump(sampled_indices, file)\n",
    "\n",
    "# Load sampled tweets DataFrame from pickle file\n",
    "sampled_tweets = pd.read_pickle(\"sampled_tweets.pkl\")\n",
    "\n",
    "# Generate new indices for additional 1000 rows\n",
    "additional_indices = set()\n",
    "while len(additional_indices) < 1000:\n",
    "    index = random.randint(0, len(sampled_tweets) - 1)  # Ensure index is within valid range\n",
    "    if index not in sampled_indices:\n",
    "        additional_indices.add(index)\n",
    "\n",
    "# Sample additional 1000 rows from DataFrame\n",
    "additional_tweets = sampled_tweets.iloc[list(additional_indices)]\n",
    "\n",
    "# Combine previously sampled tweets with newly sampled tweets\n",
    "combined_tweets = pd.concat([sampled_tweets, additional_tweets], ignore_index=True)\n",
    "\n",
    "# Save combined DataFrame to CSV file\n",
    "combined_tweets.to_csv(\"2000_random_rows.csv\", index=False)\n",
    "\n",
    "# Update sampled indices with new indices\n",
    "sampled_indices = load_sampled_indices()\n",
    "sampled_indices.extend(additional_indices)\n",
    "\n",
    "# Convert indices to standard Python integers\n",
    "sampled_indices = [int(idx) for idx in sampled_indices]\n",
    "\n",
    "# Save combined indices to JSON file\n",
    "save_sampled_indices(sampled_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_envv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
