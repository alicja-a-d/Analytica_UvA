{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import multivariate_normal, bernoulli, beta, norm\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.special import expit as logistic_sigmoid\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import balanced_accuracy_score, brier_score_loss, accuracy_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "YX_train = pd.read_csv('train_dataset.csv')\n",
    "YX_test = pd.read_csv('test_dataset.csv')\n",
    "Y = YX_train['fake_binary']\n",
    "X = YX_train.drop(columns=['fake_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features and target into a single DataFrame for resampling\n",
    "df_combined = X.copy()\n",
    "df_combined['fake_binary'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the 'party_detailed' variable along with other features and target\n",
    "smote = SMOTE(random_state=42)\n",
    "df_resampled, target_resampled = smote.fit_resample(df_combined, df_combined['party_detailed'])\n",
    "\n",
    "# Ensure the target variable is correctly aligned\n",
    "#df_resampled['fake_binary'] = target_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_detailed\n",
       "1    800\n",
       "0    800\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled['party_detailed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake_binary\n",
       "0    1174\n",
       "1     426\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled['fake_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.48877103289532753\n",
      "            Iterations: 191\n",
      "            Function evaluations: 191\n",
      "            Gradient evaluations: 191\n",
      "SMOTE Model Summary:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            fake_binary   No. Observations:                 1600\n",
      "Model:                          Logit   Df Residuals:                     1564\n",
      "Method:                           MLE   Df Model:                           35\n",
      "Date:                Sun, 02 Jun 2024   Pseudo R-squ.:                  0.1566\n",
      "Time:                        16:35:26   Log-Likelihood:                -782.03\n",
      "converged:                       True   LL-Null:                       -927.19\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.615e-42\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      -1.3454      0.129    -10.396      0.000      -1.599      -1.092\n",
      "statuses_count             -0.2124      0.091     -2.342      0.019      -0.390      -0.035\n",
      "likes_per_1000followers     0.1054      0.064      1.639      0.101      -0.021       0.231\n",
      "Toxicity                    1.0255      0.083     12.296      0.000       0.862       1.189\n",
      "is_quote                    0.0897      0.201      0.445      0.656      -0.305       0.485\n",
      "apple_binary               -0.3316      0.129     -2.562      0.010      -0.585      -0.078\n",
      "topic_label_0              -0.1871      0.178     -1.051      0.293      -0.536       0.162\n",
      "topic_label_1               0.3416      0.213      1.603      0.109      -0.076       0.759\n",
      "topic_label_2              -0.2888      0.427     -0.676      0.499      -1.126       0.548\n",
      "topic_label_3               0.4330      0.359      1.206      0.228      -0.271       1.137\n",
      "topic_label_4              -1.5082      0.751     -2.007      0.045      -2.981      -0.035\n",
      "topic_label_5               0.9982      0.365      2.736      0.006       0.283       1.713\n",
      "topic_label_6               0.1139      0.550      0.207      0.836      -0.964       1.192\n",
      "topic_label_7               0.8707      0.547      1.591      0.112      -0.202       1.943\n",
      "topic_label_8              -0.0310      0.427     -0.073      0.942      -0.867       0.805\n",
      "topic_label_9               1.1369      0.545      2.086      0.037       0.069       2.205\n",
      "topic_label_10             -0.4368      0.497     -0.879      0.380      -1.411       0.538\n",
      "topic_label_11              0.2591      0.523      0.495      0.620      -0.766       1.284\n",
      "topic_label_12              1.4011      0.557      2.516      0.012       0.310       2.492\n",
      "topic_label_13             -0.2973      0.695     -0.428      0.669      -1.659       1.065\n",
      "topic_label_14              0.0122      0.584      0.021      0.983      -1.133       1.157\n",
      "topic_label_15              0.0826      0.721      0.115      0.909      -1.331       1.496\n",
      "topic_label_16              1.4675      0.574      2.555      0.011       0.342       2.593\n",
      "topic_label_17              0.7828      0.583      1.342      0.180      -0.360       1.926\n",
      "topic_label_18              0.2487      0.889      0.280      0.780      -1.494       1.991\n",
      "topic_label_19             -0.5970      0.823     -0.725      0.468      -2.211       1.017\n",
      "topic_label_20              0.5565      0.701      0.793      0.428      -0.818       1.931\n",
      "topic_label_21              0.5352      0.606      0.883      0.377      -0.653       1.724\n",
      "topic_label_22             -1.3995      1.079     -1.297      0.195      -3.515       0.716\n",
      "topic_label_23             -0.6630      1.096     -0.605      0.545      -2.811       1.485\n",
      "topic_label_24              0.2338      0.689      0.339      0.735      -1.117       1.585\n",
      "topic_label_25              0.1497      0.763      0.196      0.845      -1.347       1.646\n",
      "topic_label_26            -12.6079    260.978     -0.048      0.961    -524.115     498.900\n",
      "topic_label_27              3.0858      1.150      2.683      0.007       0.832       5.340\n",
      "topic_label_28             -0.6634      0.813     -0.816      0.414      -2.256       0.929\n",
      "party_detailed              0.1980      0.127      1.564      0.118      -0.050       0.446\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Fit the logistic regression model on the resampled data\n",
    "model = sm.Logit(df_resampled['fake_binary'], df_resampled.drop(columns=['fake_binary'])).fit_regularized(method='l1')\n",
    "print(\"SMOTE Model Summary:\")\n",
    "print(model.summary())\n",
    "pickle.dump(model, open('regression_model_Bias.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, Y)\n",
    "\n",
    "# Convert resampled data back to DataFrame for compatibility with statsmodels\n",
    "X_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "y_resampled = pd.Series(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake_binary\n",
       "1    1055\n",
       "0    1055\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.5700030904332745\n",
      "            Iterations: 219\n",
      "            Function evaluations: 219\n",
      "            Gradient evaluations: 219\n",
      "SMOTE Model Summary:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            fake_binary   No. Observations:                 2110\n",
      "Model:                          Logit   Df Residuals:                     2074\n",
      "Method:                           MLE   Df Model:                           35\n",
      "Date:                Sun, 02 Jun 2024   Pseudo R-squ.:                  0.1777\n",
      "Time:                        16:35:30   Log-Likelihood:                -1202.7\n",
      "converged:                       True   LL-Null:                       -1462.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.241e-87\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                       0.2103      0.099      2.124      0.034       0.016       0.404\n",
      "statuses_count             -0.3050      0.071     -4.311      0.000      -0.444      -0.166\n",
      "likes_per_1000followers     0.0645      0.054      1.192      0.233      -0.042       0.171\n",
      "Toxicity                    0.9805      0.058     16.842      0.000       0.866       1.095\n",
      "is_quote                   -0.2381      0.174     -1.369      0.171      -0.579       0.103\n",
      "apple_binary               -0.3205      0.103     -3.101      0.002      -0.523      -0.118\n",
      "topic_label_0              -0.6117      0.137     -4.453      0.000      -0.881      -0.342\n",
      "topic_label_1              -0.2042      0.168     -1.215      0.224      -0.534       0.125\n",
      "topic_label_2              -1.3759      0.379     -3.628      0.000      -2.119      -0.633\n",
      "topic_label_3              -0.5861      0.312     -1.881      0.060      -1.197       0.025\n",
      "topic_label_4              -2.9137      0.750     -3.887      0.000      -4.383      -1.444\n",
      "topic_label_5               0.2106      0.304      0.693      0.488      -0.385       0.806\n",
      "topic_label_6              -1.2365      0.550     -2.250      0.024      -2.314      -0.159\n",
      "topic_label_7              -0.4646      0.516     -0.901      0.368      -1.475       0.546\n",
      "topic_label_8              -1.1293      0.380     -2.973      0.003      -1.874      -0.385\n",
      "topic_label_9              -0.0215      0.489     -0.044      0.965      -0.980       0.937\n",
      "topic_label_10             -1.6122      0.447     -3.606      0.000      -2.489      -0.736\n",
      "topic_label_11             -0.5420      0.418     -1.298      0.194      -1.361       0.277\n",
      "topic_label_12              0.7626      0.476      1.602      0.109      -0.170       1.696\n",
      "topic_label_13             -1.4655      0.624     -2.348      0.019      -2.689      -0.242\n",
      "topic_label_14             -1.2129      0.547     -2.217      0.027      -2.285      -0.141\n",
      "topic_label_15             -0.9730      0.656     -1.483      0.138      -2.259       0.313\n",
      "topic_label_16              0.3110      0.521      0.597      0.550      -0.709       1.331\n",
      "topic_label_17             -0.3609      0.540     -0.668      0.504      -1.420       0.698\n",
      "topic_label_18             -1.2671      0.886     -1.430      0.153      -3.004       0.470\n",
      "topic_label_19             -2.0235      0.822     -2.463      0.014      -3.634      -0.413\n",
      "topic_label_20             -0.6161      0.662     -0.931      0.352      -1.913       0.681\n",
      "topic_label_21             -0.5602      0.567     -0.988      0.323      -1.671       0.551\n",
      "topic_label_22             -2.8407      1.079     -2.632      0.008      -4.956      -0.725\n",
      "topic_label_23             -2.1328      1.089     -1.959      0.050      -4.267       0.002\n",
      "topic_label_24             -0.9847      0.639     -1.541      0.123      -2.237       0.268\n",
      "topic_label_25             -0.7899      0.659     -1.199      0.231      -2.082       0.502\n",
      "topic_label_26            -13.1417    168.930     -0.078      0.938    -344.238     317.954\n",
      "topic_label_27              1.6732      1.136      1.473      0.141      -0.554       3.900\n",
      "topic_label_28             -1.8893      0.821     -2.301      0.021      -3.499      -0.280\n",
      "party_detailed              0.0672      0.101      0.665      0.506      -0.131       0.265\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fit the logistic regression model on the resampled data\n",
    "model_smote = sm.Logit(y_resampled, X_resampled).fit_regularized(method='l1')\n",
    "print(\"SMOTE Model Summary:\")\n",
    "print(model_smote.summary())\n",
    "pickle.dump(model_smote, open('regression_model_Bias2.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
